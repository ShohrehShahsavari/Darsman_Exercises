





pip install missingno


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import missingno as msno





df=pd.read_csv('E:/Python Projects/shohreh/Shohreh_GitHub_Repository/Darsman_Exercises/term 5/3 - Air pollution/Air_pollution_ dataset.csv', delimiter=';')
df.head(2)


df.info()





df.shape


df.isnull().sum()


df.duplicated().sum()





# Missing values visualize with Matrix
msno.matrix(df)
plt.title('Number of Missing values in Dataset')
plt.show()





# Missing values visualize with Bar
msno.bar(df, color="skyblue")
plt.title("Number of Not NULL values in Dataset")
plt.show()





# Uniqe Values of each columns
pd.DataFrame(df.nunique(), columns=['Number of unique values'])


# function to return Top value number
def Value_count(col,Top_no=10):
    """
    Returns the top N unique values and their counts for a specified column.

    Parameters:
    - col (str): The column name for which to calculate value counts.
    - top_n (int): The number of top unique values to return (default is 10).

    Returns:
    - pd.DataFrame: A DataFrame containing the top N unique values and their counts.
    """
    return pd.DataFrame(df[col].value_counts()).head(Top_no)


Value_count('Time')


Value_count('CO(GT)',20)


df.describe().T








# Drop entirely null columns
df.dropna(axis=1, how='all', inplace=True)
df.isnull().sum()


# Drop entirely null columns
df.dropna(axis=1, how='all', inplace=True)
df.isnull().sum()


# Drop entirely null rows
df.dropna(axis=0, how='all', inplace=True)
df.info()


df.columns





df['Date']=pd.to_datetime(df['Date'], format= 'mixed')





# replace '.' with ':'  for modify format
df['Time']=df['Time'].str.replace('.', ':')

# change 'Time' column type to datetime and Hour
df['Time'] = pd.to_datetime(df['Time'], format='%H:%M:%S').dt.hour

# Rename columns from 'Time' to 'Hour'
df=df.rename(columns={ 'Time' : 'Hour' })





def change_columns_type (columns):
    '''
    Convert specified columns to numeric type, handling decimal separators.
    Parameters:
    -----------
    columns: List of column names to convert
    '''
    for col in columns:
        # replace ',' with '.' for each column
        df[col] = df[col].str.replace(',', '.')
        
        # change 'col' column type to float
        df[col] = df[col].astype('float')


change_columns_type(['CO(GT)', 'C6H6(GT)', 'T', 'RH', 'AH'])


df.info()





df.replace(-200, np.nan, inplace= True)
df.info()


df['CO(GT)'] = df.groupby(['PT08.S1(CO)', 'Hour'])['CO(GT)'].transform( lambda x: x.fillna(x.mean()))


df.info()


'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH'
